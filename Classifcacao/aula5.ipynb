{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 5 | Validação dos Modelos\n",
    "\n",
    "### 5.1 | Matriz de Confusão\n",
    "\n",
    "Para validar os modelos vamos utilizar a **matriz de confusão**. A matriz de confusão é uma tabela que mostra as **frequências de classificação** para cada classe do modelo. A ideia é verificar se o modelo está classificando corretamente as classes.\n",
    "\n",
    "A matriz de confusão é dividia em quatro partes:\n",
    "\n",
    "* **Verdadeiro Positivo (VP)**: quando o modelo classifica corretamente uma classe.\n",
    "\n",
    "* **Verdadeiro Negativo (VN)**: quando o modelo classifica corretamente uma classe.\n",
    "\n",
    "* **Falso Positivo (FP)**: quando o modelo classifica incorretamente uma classe.\n",
    "\n",
    "* **Falso Negativo (FN)**: quando o modelo classifica incorretamente uma classe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dados = pd.read_csv('Customer-Churn.csv')\n",
    "dados.head()\n",
    "\n",
    "#modificação de forma manual \n",
    "traducao_dic = {'Sim': 1, \n",
    "                'Nao': 0}\n",
    "\n",
    "dadosmodificados = dados[['Conjuge', 'Dependentes', 'TelefoneFixo', 'PagamentoOnline', 'Churn']].replace(traducao_dic)\n",
    "dadosmodificados.head()\n",
    "\n",
    "#transformação pelo get_dummies\n",
    "dummie_dados = pd.get_dummies(dados.drop(['Conjuge', 'Dependentes', 'TelefoneFixo', 'PagamentoOnline', 'Churn'],\n",
    "                axis=1))\n",
    "\n",
    "#junção dos dados trasformados com os que já tinhamos\n",
    "dados_final = pd.concat([dadosmodificados, dummie_dados], axis=1)\n",
    "\n",
    "#Divisão em inputs e outputs\n",
    "x = dados_final.drop('Churn', axis = 1)\n",
    "y = dados_final['Churn']\n",
    "\n",
    "norm = StandardScaler()\n",
    "\n",
    "X_normalizado = norm.fit_transform(x)\n",
    "X_normalizado\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_normalizado, y, test_size=0.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(metric='euclidean')\n",
    "knn.fit(X_treino, y_treino)\n",
    "predito_knn = knn.predict(X_teste)\n",
    "#predito_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(binarize=0.52)\n",
    "bnb.fit(X_treino, y_treino)\n",
    "predito_bnb = bnb.predict(X_teste)\n",
    "#predito_bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dtc.fit(X_treino, y_treino)\n",
    "predito_ArvoreDecisao = dtc.predict(X_teste)\n",
    "#predito_ArvoreDecisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1305  218]\n",
      " [ 317  273]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste, predito_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1058  465]\n",
      " [ 120  470]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste, predito_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1249  274]\n",
      " [ 290  300]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste, predito_ArvoreDecisao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 | Acurácia\n",
    "\n",
    "A partir do cálculo da **matriz de confusão** conseguimos inferir outras métricas, como por exemplo a **acurácia**. A acurácia é uma métrica que mede a taxa de acertos do modelo, ou seja, a porcentagem de acertos do modelo em relação ao total de amostras. A acurácia é calculada da seguinte forma:\n",
    "\n",
    "$$ACC = \\frac{VP + VN}{VP + VN + FP + FN}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7468054898248935\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "print(accuracy_score(y_teste, predito_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7231424514907714\n"
     ]
    }
   ],
   "source": [
    "# Bnb\n",
    "print(accuracy_score(y_teste, predito_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7330809275911027\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_teste, predito_ArvoreDecisao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 | Precisão\n",
    "\n",
    "Outra métrica importante é a **precisão**, que calcula quantos foram **classificados corretamente como positivos**\n",
    "\n",
    "$$PS = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5560081466395111\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "print(precision_score(y_teste, predito_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5026737967914439\n"
     ]
    }
   ],
   "source": [
    "# BNB\n",
    "print(precision_score(y_teste, predito_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5226480836236934\n"
     ]
    }
   ],
   "source": [
    "# Árvore de Decisão\n",
    "print(precision_score(y_teste, predito_ArvoreDecisao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 | Recall\n",
    "\n",
    "O recall é a p**roporção de positivos que foram corretamente identificados**. Ou seja, a proporção de positivos que foram classificados como positivos.\n",
    "\n",
    "$$RC = \\frac{VP}{VP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46271186440677964\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "print(recall_score(y_teste, predito_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7966101694915254\n"
     ]
    }
   ],
   "source": [
    "# BNB\n",
    "print(recall_score(y_teste, predito_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084745762711864\n"
     ]
    }
   ],
   "source": [
    "# Árvore \n",
    "print(recall_score(y_teste, predito_ArvoreDecisao))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
